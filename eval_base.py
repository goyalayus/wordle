# -*- coding: utf-8 -*-
"""eval-base.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZgIF2yEbmuKFaiDnB7Tcm9_Yf6Q4PwOd
"""

# Install latest transformers for Qwen 3 support
!pip install -q transformers torch accelerate requests

import torch
import json
import requests
import re
import csv
import os
from transformers import AutoModelForCausalLM, AutoTokenizer

# 1. Fetch the 100 eval words from your repo
URL = "https://raw.githubusercontent.com/goyalayus/wordle/main/data/eval_words.json"
eval_words = requests.get(URL).json()
print(f"Loaded {len(eval_words)} evaluation words.")

# 2. Load Qwen 3 0.6B
model_id = "Qwen/Qwen3-0.6B" # Or Qwen3-0.6B-Instruct
print(f"Loading {model_id} in BF16...")

tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True
)

def get_wordle_feedback(guess, secret):
    """Calculates G/Y/X feedback for a 5-letter guess."""
    guess, secret = guess.lower(), secret.lower()
    feedback = ["X"] * 5
    secret_list = list(secret)
    guess_list = list(guess)

    # First pass: Greens
    for i in range(5):
        if guess_list[i] == secret_list[i]:
            feedback[i] = "G"
            secret_list[i] = None
            guess_list[i] = None

    # Second pass: Yellows
    for i in range(5):
        if guess_list[i] is not None and guess_list[i] in secret_list:
            feedback[i] = "Y"
            secret_list[secret_list.index(guess_list[i])] = None

    return " ".join(feedback)

def extract_guess_q3(text):
    """
    Extract a 5-letter guess from:
    - <guess>[word]</guess> or <guess>word</guess>
    - <WORD> (e.g. <BREAD>) but not <think>
    - [WORD]
    Does NOT fall back to random 5-letter words.
    """
    if not text:
        return None

    # Remove think blocks; handle unclosed <think> too
    text_wo_think = re.sub(r"<think>.*?(</think>|$)", " ", text, flags=re.DOTALL | re.IGNORECASE)

    # 1) Preferred: <guess>...</guess> with optional square brackets
    m = re.search(r"<guess>\s*\[?([a-zA-Z]{5})\]?\s*</guess>", text_wo_think, re.IGNORECASE)
    if m:
        return m.group(1).lower()

    # 2) Accept "<BREAD>" style (exactly 5 letters), but avoid matching <think>
    m = re.search(r"<\s*([a-zA-Z]{5})\s*>", text_wo_think)
    if m and m.group(1).lower() != "think":
        return m.group(1).lower()

    # 3) Accept "[BREAD]" anywhere
    m = re.search(r"\[\s*([a-zA-Z]{5})\s*\]", text_wo_think)
    if m:
        return m.group(1).lower()

    return None

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# Trying the 3B/4B class model
# If Qwen 3 4B doesn't exist on HF yet, swap this string to "Qwen/Qwen2.5-3B-Instruct"
model_id = "Qwen/Qwen2.5-3B-Instruct"

print(f"Loading {model_id} in BF16...")

tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16, # Native weight loading
    device_map="auto",          # Handles the 7GB memory allocation efficiently
    trust_remote_code=True
)

import csv
import json
import os
import re
import torch
from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown

console = Console()
RESULTS_FILE = "qwen_midsize_baseline_results.csv"

# --- 1. HELPER FUNCTIONS (Ensuring they are defined) ---
def get_wordle_feedback(guess, secret):
    """Calculates G/Y/X feedback for a 5-letter guess."""
    guess, secret = guess.lower(), secret.lower()
    feedback = ["X"] * 5
    secret_list = list(secret)
    guess_list = list(guess)

    # First pass: Greens
    for i in range(5):
        if guess_list[i] == secret_list[i]:
            feedback[i] = "G"
            secret_list[i] = None
            guess_list[i] = None

    # Second pass: Yellows
    for i in range(5):
        if guess_list[i] is not None and guess_list[i] in secret_list:
            feedback[i] = "Y"
            secret_list[secret_list.index(guess_list[i])] = None

    return " ".join(feedback)

def format_feedback_visual(guess, feedback_str):
    """Visualizes feedback with emojis"""
    codes = feedback_str.split()
    visual = []
    for code in codes:
        if code == "G": visual.append("üü©")
        elif code == "Y": visual.append("üü®")
        else: visual.append("‚¨õ")
    return " ".join(visual)

def extract_guess_q3(text):
    """Extracts [word] from <guess> tags or fallback brackets."""
    match = re.search(r"<guess>\s*\[([a-zA-Z]{5})\]\s*</guess>", text, re.IGNORECASE)
    if match: return match.group(1).lower()
    match = re.search(r"\[([a-zA-Z]{5})\]", text)
    if match: return match.group(1).lower()
    return None

# --- 2. SETUP CSV ---
if not os.path.exists(RESULTS_FILE):
    with open(RESULTS_FILE, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["word", "won", "turns", "hallucinated", "full_chat"])

# --- 3. SYSTEM PROMPT (Excatly as requested) ---
system_prompt = (
    "You are an expert AI playing Wordle.\n"
    "GOAL: Guess the secret 5-letter word in 6 tries.\n\n"
    "CRITICAL:\n"
    "- Each game is independent. Do NOT reuse any words, reasoning, or guesses from any example or previous game.\n"
    "- Only use the user's provided guesses and feedback from THIS game to decide the next guess.\n"
    "- Never repeat a previous guess from this game.\n"
    "- Always follow the required output format exactly.\n\n"
    "FEEDBACK MEANING (per letter):\n"
    "- G (Green): correct letter in the correct position.\n"
    "- Y (Yellow): letter is in the word but in the wrong position.\n"
    "- X (Gray): letter is not in the word.\n"
    "  Duplicate-letter rule: if a letter appears multiple times in a guess, and at least one instance is G or Y,\n"
    "  then any X for that same letter means 'no additional copies beyond the confirmed count'.\n\n"
    "LOGIC RULES:\n"
    "- Keep all G letters fixed in their positions.\n"
    "- For Y letters: keep the letter in the word but forbid that specific position.\n"
    "- For X letters: eliminate the letter unless duplicate-letter rule applies.\n"
    "- Your next guess must satisfy all constraints so far.\n"
    "- On the first turn (no feedback yet), choose a strong common 5-letter starting word with unique letters.\n\n"
    "INPUT YOU WILL RECEIVE:\n"
    "- First turn: 'NEW GAME STARTED...' with no feedback.\n"
    "- Later turns: lines like:\n"
    "  Assistant previous guess: [CRANE]\n"
    "  Feedback: X X Y G G\n"
    "5 guesses left.\n\n"
    "OUTPUT FORMAT (MUST MATCH EXACTLY):\n"
    "<guess>[word]</guess>\n\n"
    "OUTPUT CONSTRAINTS:\n"
    "- [word] must be exactly 5 lowercase letters a-z.\n"
    "- Do not output anything else.\n"
    "you must must follow this output format i gave you"
)


base_user_prompt = "NEW GAME STARTED. A secret word has been chosen. Enter your first guess."

# --- 4. MAIN GAME LOOP ---
for word_idx, target_word in enumerate(eval_words):
    console.print(f"\n[bold cyan]{'='*60}[/bold cyan]")
    console.print(f"GAME [bold cyan]{word_idx+1}/100[/bold cyan] | TARGET: [bold magenta]{target_word.upper()}[/bold magenta]")
    console.print(f"[bold cyan]{'='*60}[/bold cyan]")

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": base_user_prompt},
    ]

    won = False
    hallucinated = False
    turns = 0

    for turn in range(6):
        turns += 1

        # Prefix forcing to ensure thinking starts
        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        text += "<think>\n"

        inputs = tokenizer([text], return_tensors="pt").to("cuda")

        with torch.no_grad():
            generated_ids = model.generate(
                **inputs,
                max_new_tokens=1024,
                do_sample=False,
                pad_token_id=tokenizer.eos_token_id,
                stop_strings=["</guess>"], # Stop exactly after guess
                tokenizer=tokenizer
            )

        response_ids = generated_ids[0][len(inputs.input_ids[0]) :]
        partial_response = tokenizer.decode(response_ids, skip_special_tokens=True).strip()
        response = "<think>\n" + partial_response

        # Log Logic
        think_match = re.search(r"<think>(.*?)</think>", response, re.DOTALL)
        if think_match:
            console.print(Panel(Markdown(think_match.group(1).strip()), title=f"[dim]Turn {turn} Analysis[/dim]", border_style="dim"))

        # Log Raw if debug needed
        # console.print(f"[dim]{response}[/dim]")

        guess = extract_guess_q3(response)

        if not guess:
            console.print(f"[bold red]‚ùå FORMAT ERROR: Could not extract word from response.[/bold red]")
            hallucinated = True
            messages.append({"role": "assistant", "content": response})
            # Hard reset instruction
            messages.append({"role": "user", "content": "ERROR. Output ONLY: <guess>[word]</guess>"})
            continue

        feedback = get_wordle_feedback(guess, target_word)
        visual = format_feedback_visual(guess, feedback)
        console.print(f"GUESS: [bold white on blue] {guess.upper()} [/bold white on blue]  {visual}")

        if guess == target_word:
            won = True
            console.print(f"[bold green]üèÜ WINNER in {turns} turns![/bold green]")
            break

        messages.append({"role": "assistant", "content": response})
        messages.append({"role": "user", "content": f"Previous: [{guess.upper()}]\nFeedback: {feedback}\n{5-turn} guesses left."})

    with open(RESULTS_FILE, "a", newline="") as f:
        writer = csv.writer(f)
        writer.writerow([target_word, won, turns, hallucinated, json.dumps(messages)])

print("\nEvaluation Complete!")